{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec00b52a-f23e-490b-8c42-c07d7a3a30b9",
   "metadata": {},
   "source": [
    "## Design\n",
    "1. tasks it needs to run gets appended to a task queue (which it queries from s3 accordingly using the directory of the file)\n",
    "2. it processes tasks in batches of M. After each batch is complete, it sends \"OK\" to another json. It also updates its task queue from s3 (deletes these 20, and takes in more if more were added onto it)\n",
    "3. If it fails for any task, it sents \"NOT OK\" and the tasks on its taskqueue to s3 and script stops. Then batch_manager will kill that gpu and redistribute the tasks to an alive gpu.\n",
    "4. Once a gpu's task queue is empty, it dies.\n",
    "    - if the last gpu fails early, it'll tell batch manager that there were some tasks left over. then you just need to rerun those tasks when you wake up\n",
    "    - so the system won't be perfect, but it's risk free, and cost efficient, and it does make it a whole lot less annoying.\n",
    "    - also later on you can increase risk tolerance (say it only dies early if it fails some percentage of jobs, and failed jobs get added to some dead letter queue. But I'm not adding that in right now.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c299635-80ab-4c08-a727-d77ffedf6d79",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: psutil in /usr/lib/python3/dist-packages (5.9.0)\n",
      "\u001b[33mDEPRECATION: flatbuffers 1.12.1-git20200711.33e2d80-dfsg1-0.6 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of flatbuffers or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.34.156-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting botocore<1.35.0,>=1.34.156 (from boto3)\n",
      "  Downloading botocore-1.34.156-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3)\n",
      "  Downloading s3transfer-0.10.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in ./.local/lib/python3.10/site-packages (from botocore<1.35.0,>=1.34.156->boto3) (2.8.2)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/lib/python3/dist-packages (from botocore<1.35.0,>=1.34.156->boto3) (1.26.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.156->boto3) (1.16.0)\n",
      "Downloading boto3-1.34.156-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading botocore-1.34.156-py3-none-any.whl (12.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m198.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading s3transfer-0.10.2-py3-none-any.whl (82 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[33mDEPRECATION: flatbuffers 1.12.1-git20200711.33e2d80-dfsg1-0.6 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of flatbuffers or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: jmespath, botocore, s3transfer, boto3\n",
      "Successfully installed boto3-1.34.156 botocore-1.34.156 jmespath-1.0.1 s3transfer-0.10.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.44.0-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch in /usr/lib/python3/dist-packages (2.0.1)\n",
      "Collecting huggingface_hub\n",
      "  Downloading huggingface_hub-0.24.5-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.local/lib/python3.10/site-packages (from transformers) (1.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers) (5.4.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.7.24-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in ./.local/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./.local/lib/python3.10/site-packages (from transformers) (4.66.1)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface_hub)\n",
      "  Downloading fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.local/lib/python3.10/site-packages (from huggingface_hub) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.local/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->transformers) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers) (2020.6.20)\n",
      "Downloading transformers-4.44.0-py3-none-any.whl (9.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m166.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.24.5-py3-none-any.whl (417 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.5/417.5 kB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.7.24-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (776 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.5/776.5 kB\u001b[0m \u001b[31m121.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m435.5/435.5 kB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m203.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[33mDEPRECATION: flatbuffers 1.12.1-git20200711.33e2d80-dfsg1-0.6 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of flatbuffers or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: safetensors, regex, fsspec, huggingface_hub, tokenizers, transformers\n",
      "Successfully installed fsspec-2024.6.1 huggingface_hub-0.24.5 regex-2024.7.24 safetensors-0.4.4 tokenizers-0.19.1 transformers-4.44.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install psutil\n",
    "!pip install boto3\n",
    "!pip install transformers torch huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "667654ac-a5d1-4391-bbd0-e71ed9faccd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError, PartialCredentialsError\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed8edb27-8568-41c5-9fae-f2fa334e6113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "An error occurred (InvalidClientTokenId) when calling the GetCallerIdentity operation: The security token included in the request is invalid.\n"
     ]
    }
   ],
   "source": [
    "os.environ['AWS_ACCESS_KEY_ID'] = 'key1'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = 'key2'\n",
    "os.environ['AWS_DEFAULT_REGION'] = 'us-east-1'\n",
    "!aws sts get-caller-identity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ef2d4b-3000-452b-9ad3-b61659b487fe",
   "metadata": {},
   "source": [
    "## Inject Model for Inference\n",
    "\n",
    "- this is just for llm ops, not multimodal ops, so just a simple inference function should be ok\n",
    "- Super modular (just inject your inference code here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5df693bf-fa8e-4b27-bb9a-56ae599270cd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eabffc55c1e4410e9029f2d83b9b62ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/735 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2ec0069b04b4095b8939154c55c7101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/35.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "253b15de86374f44ab2836c3b26e46a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31af634e4e1d45eba1dd0c920bb61ca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fa72aceea2c4c87b53967d516d41205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/564M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ecdb8694624ff09b58c41300e50186",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7b7ff55682c4366b039af34c5681143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3bc1102c74f4e2fa02abc22df10d6c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/7.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "501625d8ae6f4f2ba01fc79385266db8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49cf207bbe044fa59acfb881af2ba9c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d927e3a6bae14c7da7fe6aaa3f21cc14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54b7bb968b79494c878b717e0d4233cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/1.08k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01fcd8da4963499abfb01961542c2aee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "torch.set_default_device(\"cuda\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-2\", torch_dtype=\"auto\", trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-2\", trust_remote_code=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de1a67a3-3265-4e83-904a-44bb1bd82264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(input_text):\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "    inputs = inputs.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            inputs.input_ids,\n",
    "            attention_mask=inputs.attention_mask,\n",
    "            max_new_tokens=200,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9e1173-e830-4704-bb70-a86fad59b3e9",
   "metadata": {},
   "source": [
    "## The Worker \n",
    "\n",
    "-  cluster_num and bucket_name need to be inputted. Everything else is good as-is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "126ff311-63b6-4d15-8d02-efb9514caa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file_to_dict(bucket_name, object_name):\n",
    "    try:\n",
    "        response = s3.get_object(Bucket=bucket_name, Key=object_name)\n",
    "        content = response['Body'].read().decode('utf-8')\n",
    "        data_dict = json.loads(content)\n",
    "        # print(f'File {object_name} downloaded from bucket {bucket_name} and converted to dictionary.')\n",
    "        return data_dict\n",
    "    except (NoCredentialsError, PartialCredentialsError):\n",
    "        print('Credentials not available.')\n",
    "    except Exception as e:\n",
    "        print(f'An error occurred: {e}')\n",
    "        return None\n",
    "\n",
    "def upload_dict_to_s3(bucket_name, object_name, dictionary):\n",
    "    json_data = json.dumps(dictionary)\n",
    "    s3.put_object(Bucket=bucket_name, Key=object_name, Body=json_data)\n",
    "\n",
    "def create_bucket(bucket_name, region=None):\n",
    "    try:\n",
    "        if region:\n",
    "            s3.create_bucket(\n",
    "                Bucket=bucket_name,\n",
    "                # CreateBucketConfiguration={'LocationConstraint': region}\n",
    "            )\n",
    "        else:\n",
    "            s3.create_bucket(Bucket=bucket_name)\n",
    "        print(f'Bucket {bucket_name} created successfully.')\n",
    "    except s3.exceptions.BucketAlreadyExists:\n",
    "        print(f'Bucket {bucket_name} already exists.')\n",
    "    except s3.exceptions.BucketAlreadyOwnedByYou:\n",
    "        print(f'Bucket {bucket_name} is already owned by you.')\n",
    "    except (NoCredentialsError, PartialCredentialsError):\n",
    "        print('Credentials not available.')\n",
    "\n",
    "region = 'us-east-1'\n",
    "cluster_num = 3 #hardcode which batch_num this gpu is associated with.\n",
    "bucket_name = f\"rapper-vkg-{cluster_num}\"\n",
    "process_batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ef902d5-dab7-415e-8f4e-b31f79289e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "063a9bf4-da53-4630-88e0-f565a44a83f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "taskqueue_dict = download_file_to_dict(bucket_name, f\"task_queue_{cluster_num}.json\")\n",
    "taskqueue = taskqueue_dict[\"task_queue\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4dff32a8-a5aa-4759-b45e-181ca01094df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket rapper-vkg-3-results created successfully.\n"
     ]
    }
   ],
   "source": [
    "create_bucket(f\"{bucket_name}-results\", region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae72898a-3fb1-427b-88cc-266b4044feb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#just one prompt. p ez to refactor to multiprompt.\n",
    "prompt = \"Is this politically correct? If so, explain why?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a585cef-d359-40ce-b31a-20f0c320fc85",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_3.json\n",
      "data_3.json has been completed\n",
      "data_10.json\n",
      "data_10.json has been completed\n",
      "data_17.json\n",
      "data_17.json has been completed\n",
      "data_24.json\n",
      "data_24.json has been completed\n",
      "data_31.json\n",
      "data_31.json has been completed\n",
      "data_38.json\n",
      "data_38.json has been completed\n",
      "data_45.json\n",
      "data_45.json has been completed\n",
      "data_52.json\n",
      "data_52.json has been completed\n",
      "data_59.json\n",
      "data_59.json has been completed\n",
      "data_66.json\n",
      "data_66.json has been completed\n",
      "A batch of size 10 has been completed\n",
      "Length of taskqueue:  58\n",
      "data_465.json\n",
      "data_465.json has been completed\n",
      "data_150.json\n",
      "data_150.json has been completed\n",
      "data_381.json\n",
      "data_381.json has been completed\n",
      "data_472.json\n",
      "data_472.json has been completed\n",
      "data_325.json\n",
      "data_325.json has been completed\n",
      "data_353.json\n",
      "data_353.json has been completed\n",
      "data_241.json\n",
      "data_241.json has been completed\n",
      "data_122.json\n",
      "data_122.json has been completed\n",
      "data_283.json\n",
      "data_283.json has been completed\n",
      "data_262.json\n",
      "data_262.json has been completed\n",
      "A batch of size 10 has been completed\n",
      "Length of taskqueue:  58\n",
      "data_324.json\n",
      "data_324.json has been completed\n",
      "data_198.json\n",
      "data_198.json has been completed\n",
      "data_296.json\n",
      "data_296.json has been completed\n",
      "data_220.json\n",
      "data_220.json has been completed\n",
      "data_339.json\n",
      "data_339.json has been completed\n",
      "data_135.json\n",
      "data_135.json has been completed\n",
      "data_408.json\n",
      "data_408.json has been completed\n",
      "data_101.json\n",
      "data_101.json has been completed\n",
      "data_94.json\n",
      "data_94.json has been completed\n",
      "data_451.json\n",
      "data_451.json has been completed\n",
      "A batch of size 10 has been completed\n",
      "Length of taskqueue:  48\n",
      "data_129.json\n",
      "data_129.json has been completed\n",
      "data_444.json\n",
      "data_444.json has been completed\n",
      "data_423.json\n",
      "data_423.json has been completed\n",
      "data_275.json\n",
      "data_275.json has been completed\n",
      "data_331.json\n",
      "data_331.json has been completed\n",
      "data_115.json\n",
      "data_115.json has been completed\n",
      "data_458.json\n",
      "data_458.json has been completed\n",
      "data_136.json\n",
      "data_136.json has been completed\n",
      "data_227.json\n",
      "data_227.json has been completed\n",
      "data_430.json\n",
      "data_430.json has been completed\n",
      "A batch of size 10 has been completed\n",
      "Length of taskqueue:  48\n",
      "data_477.json\n",
      "data_477.json has been completed\n",
      "data_183.json\n",
      "data_183.json has been completed\n",
      "data_162.json\n",
      "data_162.json has been completed\n",
      "data_323.json\n",
      "data_323.json has been completed\n",
      "data_219.json\n",
      "data_219.json has been completed\n",
      "data_402.json\n",
      "data_402.json has been completed\n",
      "data_157.json\n",
      "data_157.json has been completed\n",
      "data_234.json\n",
      "data_234.json has been completed\n",
      "data_199.json\n",
      "data_199.json has been completed\n",
      "data_297.json\n",
      "data_297.json has been completed\n",
      "A batch of size 10 has been completed\n",
      "Length of taskqueue:  38\n",
      "data_346.json\n",
      "data_346.json has been completed\n",
      "data_374.json\n",
      "data_374.json has been completed\n",
      "data_143.json\n",
      "data_143.json has been completed\n",
      "data_388.json\n",
      "data_388.json has been completed\n",
      "data_311.json\n",
      "data_311.json has been completed\n",
      "data_416.json\n",
      "data_416.json has been completed\n",
      "data_332.json\n",
      "data_332.json has been completed\n",
      "data_318.json\n",
      "data_318.json has been completed\n",
      "data_276.json\n",
      "data_276.json has been completed\n",
      "data_80.json\n",
      "data_80.json has been completed\n",
      "A batch of size 10 has been completed\n",
      "Length of taskqueue:  48\n",
      "data_294.json\n",
      "data_294.json has been completed\n",
      "data_449.json\n",
      "data_449.json has been completed\n",
      "data_364.json\n",
      "data_364.json has been completed\n",
      "data_478.json\n",
      "data_478.json has been completed\n",
      "data_310.json\n",
      "data_310.json has been completed\n",
      "data_252.json\n",
      "data_252.json has been completed\n",
      "data_346.json\n",
      "data_346.json has been completed\n",
      "data_374.json\n",
      "data_374.json has been completed\n",
      "data_143.json\n",
      "data_143.json has been completed\n",
      "data_388.json\n",
      "data_388.json has been completed\n",
      "A batch of size 10 has been completed\n",
      "Length of taskqueue:  38\n",
      "data_105.json\n",
      "data_105.json has been completed\n",
      "data_175.json\n",
      "data_175.json has been completed\n",
      "data_311.json\n",
      "data_311.json has been completed\n",
      "data_245.json\n",
      "data_245.json has been completed\n",
      "data_416.json\n",
      "data_416.json has been completed\n",
      "data_332.json\n"
     ]
    }
   ],
   "source": [
    "while(taskqueue):\n",
    "    try:\n",
    "        for i in range(min(process_batch_size, len(taskqueue))):\n",
    "            file = taskqueue[i]\n",
    "            print(file)\n",
    "            tf = download_file_to_dict(bucket_name, file)\n",
    "            context = tf[\"text\"]\n",
    "            full_prompt = f\"\"\"\n",
    "            CONTEXT: \n",
    "            {context}\n",
    "\n",
    "            PROMPT: \n",
    "            {prompt}\n",
    "            \"\"\"\n",
    "            tf.update(\n",
    "                {\n",
    "                    \"model_inference\": run_model(full_prompt)\n",
    "                }\n",
    "            )\n",
    "            upload_dict_to_s3(f\"{bucket_name}-results\", f\"{file}_results.json\", tf)\n",
    "            print(f\"{file} has been completed\")\n",
    "        taskqueue = taskqueue[process_batch_size:]\n",
    "        temp_taskqueue = download_file_to_dict(bucket_name, f\"task_queue_{cluster_num}.json\")[\"task_queue\"]\n",
    "        taskqueue = list(set(taskqueue)|set(temp_taskqueue[process_batch_size:]))\n",
    "        upload_dict_to_s3(bucket_name, f\"task_queue_{cluster_num}.json\", {\"task_queue\": taskqueue})\n",
    "        print(f\"A batch of size {process_batch_size} has been completed\")\n",
    "        print(\"Length of taskqueue: \", len(taskqueue))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"WORKER FAILED\")\n",
    "        taskqueue_dict[\"task_queue\"] = taskqueue\n",
    "        taskqueue_dict[\"status\"] = \"NOT OK\"\n",
    "        upload_dict_to_s3(bucket_name, f\"task_queue_{cluster_num}.json\", taskqueue_dict)\n",
    "        print(\"updated task queue\")\n",
    "        break\n",
    "\n",
    "print(\"exited process\")\n",
    "if taskqueue_dict.get(\"status\", None) != \"NOT OK\":\n",
    "    print(\"updating status to complete\")\n",
    "    taskqueue_dict[\"status\"] = \"COMPLETE\"\n",
    "    upload_dict_to_s3(bucket_name, f\"task_queue_{cluster_num}.json\", taskqueue_dict)\n",
    "else:\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
