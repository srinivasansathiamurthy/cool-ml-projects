{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d719b41-9a03-4769-87c2-f91c9b1dccf3",
   "metadata": {},
   "source": [
    "## Design\n",
    "\n",
    "1. You need to launch lambda gpus manually. Way too risky for to do that automatically.\n",
    "2. Then you run the scripts in each cluster.\n",
    "3. This script will take care of making sure gpus aren't trolling and distribute resources accordingly. Also kills gpus once they're done with their task.\n",
    "4. tasks it needs to run gets appended to a task queue (which it queries from s3 accordingly using the directory of the file)\n",
    "2. it processes tasks in batches of M. After each batch is complete, it sends \"OK\" to another json. It also updates its task queue from s3 (deletes these 20, and takes in more if more were added onto it)\n",
    "3. If it fails for any task, it sents \"NOT OK\" and the tasks on its taskqueue to s3 and script stops. Then batch_manager will kill that gpu and redistribute the tasks to an alive gpu.\n",
    "4. Once a gpu's task queue is empty, it dies.\n",
    "    - if the last gpu fails early, it'll tell batch manager that there were some tasks left over. then you just need to rerun those tasks when you wake up\n",
    "    - so the system won't be perfect, but it's risk free, and cost efficient, and it does make it a whole lot less annoying.\n",
    "    - also later on you can increase risk tolerance (say it only dies early if it fails some percentage of jobs, and failed jobs get added to some dead letter queue. But I'm not adding that in right now. (the dead letter queue exists though)\n",
    "\n",
    "**I guess there'll be a dedicated company aws account for this... if it becomes something you'd want to set up for multiple people**\n",
    "\n",
    "**But not mine though**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5fda2867-4dc7-4af3-b2f6-130595912da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError, PartialCredentialsError\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "501cd074-4e84-4310-b186-46e78fa6fd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_timeout = 3600*1 #this hard limits your expenditures (3600*1 = 1 hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5eae3670-1b5a-4e2d-b258-59cbc107482b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "An error occurred (InvalidClientTokenId) when calling the GetCallerIdentity operation: The security token included in the request is invalid.\n"
     ]
    }
   ],
   "source": [
    "os.environ['AWS_ACCESS_KEY_ID'] = 'key1'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = 'key2'\n",
    "os.environ['AWS_DEFAULT_REGION'] = 'us-east-1'\n",
    "!aws sts get-caller-identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1bb96760-5ee7-4be8-a006-53a36e845136",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SET THIS MANUALLY EACH TIME\n",
    "alive_workers = [\n",
    "    \"64.181.251.255\",\n",
    "    \"146.235.239.254\",\n",
    "    \"64.181.239.13\",\n",
    "    \"165.1.78.78\",\n",
    "    \"64.181.237.190\",\n",
    "    \"146.235.221.170\",\n",
    "    \"152.70.121.217\"\n",
    "]\n",
    "\n",
    "batch_size = 7\n",
    "worker_2_batch = {}\n",
    "for i in range(batch_size):\n",
    "    worker_2_batch[alive_workers[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "bddd92de-b74e-4528-85bb-0ae5989878a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = 'lambda_api_key'\n",
    "BASE_URL = 'https://cloud.lambdalabs.com/api/v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c7a6a772-e101-478c-9ab3-1e776f36dec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def download_file_to_dict(bucket_name, object_name):\n",
    "    try:\n",
    "        response = s3.get_object(Bucket=bucket_name, Key=object_name)\n",
    "        content = response['Body'].read().decode('utf-8')\n",
    "        data_dict = json.loads(content)\n",
    "        return data_dict\n",
    "    except (NoCredentialsError, PartialCredentialsError):\n",
    "        print('Credentials not available.')\n",
    "    except Exception as e:\n",
    "        print(f'An error occurred: {e}')\n",
    "        return None\n",
    "\n",
    "\n",
    "def upload_dict_to_s3(bucket_name, object_name, dictionary):\n",
    "    json_data = json.dumps(dictionary)\n",
    "    s3.put_object(Bucket=bucket_name, Key=object_name, Body=json_data)\n",
    "\n",
    "\n",
    "def move_s3_object(source_bucket_name, source_object_name, dest_bucket_name, dest_object_name):\n",
    "    try:\n",
    "        copy_source = {'Bucket': source_bucket_name, 'Key': source_object_name}\n",
    "        s3.copy_object(CopySource=copy_source, Bucket=dest_bucket_name, Key=dest_object_name)\n",
    "        s3.delete_object(Bucket=source_bucket_name, Key=source_object_name)\n",
    "    except (NoCredentialsError, PartialCredentialsError):\n",
    "        print('Credentials not available.')\n",
    "    except Exception as e:\n",
    "        print(f'An error occurred: {e}')\n",
    "\n",
    "\n",
    "def list_instances():\n",
    "    url = f'{BASE_URL}/instances'\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {API_KEY}',\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        instances = response.json()\n",
    "        return instances\n",
    "    else:\n",
    "        print(f'Failed to list instances. Status code: {response.status_code}, Response: {response.text}')\n",
    "        return None\n",
    "instances = list_instances()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "55b3290a-acb9-4f2e-81b9-d9bff6088bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster2id = {}\n",
    "for ele in instances[\"data\"]:\n",
    "    cluster2id[worker_2_batch[ele[\"ip\"]]] = ele[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "97a78b1a-aac0-4fee-8d4e-9b16a90fbc12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '42b3ee0e2848418eaf79cef318ef3bdd',\n",
       " 1: '941492dcac5f43daa8ebf6fbebc26f9c',\n",
       " 2: 'c07ca923c8a84ff1abc32629cff449b6',\n",
       " 3: '26619e38d69f49f6b92a6eaf4dfc4bc9',\n",
       " 4: '98827e70798b4752ac869d549c47237d',\n",
       " 5: 'bffbf93c9494494384b3bd4271952ef9',\n",
       " 6: '29934d5c96ae43c2a5b8c6723c15b80c'}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "19f6c274-73c4-4fc0-836d-1112703f4364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def terminate_instance(cluster_num):\n",
    "    BASE_URL = 'https://cloud.lambdalabs.com/api/v1/instance-operations/terminate'\n",
    "    td = {\n",
    "      \"instance_ids\": [\n",
    "        cluster2id[cluster_num]\n",
    "      ]\n",
    "    }\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    response = requests.post(\n",
    "        BASE_URL,\n",
    "        auth=(API_KEY, API_KEY),  # API key is used as the username\n",
    "        headers=headers,\n",
    "        json=td  # Payload from the INSTANCE-IDS file\n",
    "    )\n",
    "    if response.status_code == 200:\n",
    "        print(json.dumps(response.json(), indent=2))\n",
    "    else:\n",
    "        print(f'Failed to terminate instances. Status code: {response.status_code}, Response: {response.text}')\n",
    "\n",
    "bucket_name = \"rapper-vkg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "fe95a1ca-8b57-4c11-8f4a-9427411848bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "live_clusters = list(worker_2_batch.values())\n",
    "print(live_clusters)\n",
    "s3 = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f71e27c4-73a0-4aae-86b7-d8ffb6cae8f3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH MANAGER IS WORKING\n",
      "status of cluster: 0: None\n",
      "status of cluster: 1: None\n",
      "status of cluster: 2: None\n",
      "status of cluster: 3: None\n",
      "status of cluster: 4: None\n",
      "status of cluster: 5: None\n",
      "status of cluster: 6: None\n",
      "BRANCH MANAGER DIDN'T DO ANYTHING\n",
      "BATCH MANAGER IS WORKING\n",
      "status of cluster: 0: None\n",
      "status of cluster: 1: None\n",
      "status of cluster: 2: None\n",
      "status of cluster: 3: None\n",
      "status of cluster: 4: None\n",
      "status of cluster: 5: None\n",
      "status of cluster: 6: None\n",
      "BRANCH MANAGER DIDN'T DO ANYTHING\n",
      "BATCH MANAGER IS WORKING\n",
      "status of cluster: 0: None\n",
      "status of cluster: 1: None\n",
      "status of cluster: 2: None\n",
      "status of cluster: 3: None\n",
      "status of cluster: 4: None\n",
      "status of cluster: 5: None\n",
      "status of cluster: 6: None\n",
      "BRANCH MANAGER DIDN'T DO ANYTHING\n",
      "BATCH MANAGER IS WORKING\n",
      "status of cluster: 0: None\n",
      "status of cluster: 1: None\n",
      "status of cluster: 2: None\n",
      "status of cluster: 3: None\n",
      "status of cluster: 4: None\n",
      "status of cluster: 5: None\n",
      "status of cluster: 6: None\n",
      "BRANCH MANAGER DIDN'T DO ANYTHING\n",
      "BATCH MANAGER IS WORKING\n",
      "status of cluster: 0: None\n",
      "status of cluster: 1: None\n",
      "status of cluster: 2: None\n",
      "status of cluster: 3: None\n",
      "status of cluster: 4: None\n",
      "status of cluster: 5: None\n",
      "status of cluster: 6: None\n",
      "BRANCH MANAGER DIDN'T DO ANYTHING\n",
      "BATCH MANAGER IS WORKING\n",
      "status of cluster: 0: COMPLETE\n",
      "cluster number 0 complete\n",
      "status of cluster: 1: COMPLETE\n",
      "cluster number 1 complete\n",
      "status of cluster: 2: None\n",
      "status of cluster: 3: COMPLETE\n",
      "cluster number 3 complete\n",
      "status of cluster: 4: COMPLETE\n",
      "cluster number 4 complete\n",
      "status of cluster: 5: COMPLETE\n",
      "cluster number 5 complete\n",
      "status of cluster: 6: COMPLETE\n",
      "cluster number 6 complete\n",
      "KILLING USELESS LAZY GUYS\n",
      "{\n",
      "  \"data\": {\n",
      "    \"terminated_instances\": [\n",
      "      {\n",
      "        \"id\": \"42b3ee0e2848418eaf79cef318ef3bdd\",\n",
      "        \"ip\": \"64.181.251.255\",\n",
      "        \"status\": \"terminating\",\n",
      "        \"ssh_key_names\": [\n",
      "          \"Srinivasan Sathiamurthy\"\n",
      "        ],\n",
      "        \"file_system_names\": [],\n",
      "        \"region\": {\n",
      "          \"name\": \"us-west-1\",\n",
      "          \"description\": \"California, USA\"\n",
      "        },\n",
      "        \"instance_type\": {\n",
      "          \"name\": \"gpu_1x_a10\",\n",
      "          \"description\": \"1x A10 (24 GB PCIe)\",\n",
      "          \"gpu_description\": \"A10 (24 GB PCIe)\",\n",
      "          \"price_cents_per_hour\": 75,\n",
      "          \"specs\": {\n",
      "            \"vcpus\": 30,\n",
      "            \"memory_gib\": 200,\n",
      "            \"storage_gib\": 1400,\n",
      "            \"gpus\": 1\n",
      "          }\n",
      "        },\n",
      "        \"hostname\": \"64-181-251-255.cloud.lambdalabs.com\",\n",
      "        \"jupyter_token\": \"2325e26452f547a8be8377dba7044163\",\n",
      "        \"jupyter_url\": \"https://jupyter-1535e4b08eae47a4aee39c3a258fafb5.lambdaspaces.com/?token=2325e26452f547a8be8377dba7044163\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"data\": {\n",
      "    \"terminated_instances\": [\n",
      "      {\n",
      "        \"id\": \"941492dcac5f43daa8ebf6fbebc26f9c\",\n",
      "        \"ip\": \"146.235.239.254\",\n",
      "        \"status\": \"terminating\",\n",
      "        \"ssh_key_names\": [\n",
      "          \"Srinivasan Sathiamurthy\"\n",
      "        ],\n",
      "        \"file_system_names\": [],\n",
      "        \"region\": {\n",
      "          \"name\": \"us-west-1\",\n",
      "          \"description\": \"California, USA\"\n",
      "        },\n",
      "        \"instance_type\": {\n",
      "          \"name\": \"gpu_1x_a10\",\n",
      "          \"description\": \"1x A10 (24 GB PCIe)\",\n",
      "          \"gpu_description\": \"A10 (24 GB PCIe)\",\n",
      "          \"price_cents_per_hour\": 75,\n",
      "          \"specs\": {\n",
      "            \"vcpus\": 30,\n",
      "            \"memory_gib\": 200,\n",
      "            \"storage_gib\": 1400,\n",
      "            \"gpus\": 1\n",
      "          }\n",
      "        },\n",
      "        \"hostname\": \"146-235-239-254.cloud.lambdalabs.com\",\n",
      "        \"jupyter_token\": \"1b8a2f48f2c045d2bf3f5f430446d206\",\n",
      "        \"jupyter_url\": \"https://jupyter-4577b2968b0d467ab8b0d3c6d541e360.lambdaspaces.com/?token=1b8a2f48f2c045d2bf3f5f430446d206\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"data\": {\n",
      "    \"terminated_instances\": [\n",
      "      {\n",
      "        \"id\": \"26619e38d69f49f6b92a6eaf4dfc4bc9\",\n",
      "        \"ip\": \"165.1.78.78\",\n",
      "        \"status\": \"terminating\",\n",
      "        \"ssh_key_names\": [\n",
      "          \"Srinivasan Sathiamurthy\"\n",
      "        ],\n",
      "        \"file_system_names\": [],\n",
      "        \"region\": {\n",
      "          \"name\": \"us-west-1\",\n",
      "          \"description\": \"California, USA\"\n",
      "        },\n",
      "        \"instance_type\": {\n",
      "          \"name\": \"gpu_1x_a10\",\n",
      "          \"description\": \"1x A10 (24 GB PCIe)\",\n",
      "          \"gpu_description\": \"A10 (24 GB PCIe)\",\n",
      "          \"price_cents_per_hour\": 75,\n",
      "          \"specs\": {\n",
      "            \"vcpus\": 30,\n",
      "            \"memory_gib\": 200,\n",
      "            \"storage_gib\": 1400,\n",
      "            \"gpus\": 1\n",
      "          }\n",
      "        },\n",
      "        \"hostname\": \"165-1-78-78.cloud.lambdalabs.com\",\n",
      "        \"jupyter_token\": \"7de80f4cf9154755bc123631f8cdf06f\",\n",
      "        \"jupyter_url\": \"https://jupyter-041dd15d6cdd4c0abbbd7214f481ab9d.lambdaspaces.com/?token=7de80f4cf9154755bc123631f8cdf06f\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"data\": {\n",
      "    \"terminated_instances\": [\n",
      "      {\n",
      "        \"id\": \"98827e70798b4752ac869d549c47237d\",\n",
      "        \"ip\": \"64.181.237.190\",\n",
      "        \"status\": \"terminating\",\n",
      "        \"ssh_key_names\": [\n",
      "          \"Srinivasan Sathiamurthy\"\n",
      "        ],\n",
      "        \"file_system_names\": [],\n",
      "        \"region\": {\n",
      "          \"name\": \"us-west-1\",\n",
      "          \"description\": \"California, USA\"\n",
      "        },\n",
      "        \"instance_type\": {\n",
      "          \"name\": \"gpu_1x_a10\",\n",
      "          \"description\": \"1x A10 (24 GB PCIe)\",\n",
      "          \"gpu_description\": \"A10 (24 GB PCIe)\",\n",
      "          \"price_cents_per_hour\": 75,\n",
      "          \"specs\": {\n",
      "            \"vcpus\": 30,\n",
      "            \"memory_gib\": 200,\n",
      "            \"storage_gib\": 1400,\n",
      "            \"gpus\": 1\n",
      "          }\n",
      "        },\n",
      "        \"hostname\": \"64-181-237-190.cloud.lambdalabs.com\",\n",
      "        \"jupyter_token\": \"2b391bbca8e444ac833776ab0b39f50a\",\n",
      "        \"jupyter_url\": \"https://jupyter-35e9cecfd7e246d2bb536c7f88b17380.lambdaspaces.com/?token=2b391bbca8e444ac833776ab0b39f50a\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"data\": {\n",
      "    \"terminated_instances\": [\n",
      "      {\n",
      "        \"id\": \"bffbf93c9494494384b3bd4271952ef9\",\n",
      "        \"ip\": \"146.235.221.170\",\n",
      "        \"status\": \"terminating\",\n",
      "        \"ssh_key_names\": [\n",
      "          \"Srinivasan Sathiamurthy\"\n",
      "        ],\n",
      "        \"file_system_names\": [],\n",
      "        \"region\": {\n",
      "          \"name\": \"us-west-1\",\n",
      "          \"description\": \"California, USA\"\n",
      "        },\n",
      "        \"instance_type\": {\n",
      "          \"name\": \"gpu_1x_a10\",\n",
      "          \"description\": \"1x A10 (24 GB PCIe)\",\n",
      "          \"gpu_description\": \"A10 (24 GB PCIe)\",\n",
      "          \"price_cents_per_hour\": 75,\n",
      "          \"specs\": {\n",
      "            \"vcpus\": 30,\n",
      "            \"memory_gib\": 200,\n",
      "            \"storage_gib\": 1400,\n",
      "            \"gpus\": 1\n",
      "          }\n",
      "        },\n",
      "        \"hostname\": \"146-235-221-170.cloud.lambdalabs.com\",\n",
      "        \"jupyter_token\": \"8ee78277915a476a8ada8cc09597a9e5\",\n",
      "        \"jupyter_url\": \"https://jupyter-8bd15d6ac01e4779a4110b45caed911e.lambdaspaces.com/?token=8ee78277915a476a8ada8cc09597a9e5\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"data\": {\n",
      "    \"terminated_instances\": [\n",
      "      {\n",
      "        \"id\": \"29934d5c96ae43c2a5b8c6723c15b80c\",\n",
      "        \"ip\": \"152.70.121.217\",\n",
      "        \"status\": \"terminating\",\n",
      "        \"ssh_key_names\": [\n",
      "          \"Srinivasan Sathiamurthy\"\n",
      "        ],\n",
      "        \"file_system_names\": [],\n",
      "        \"region\": {\n",
      "          \"name\": \"us-west-1\",\n",
      "          \"description\": \"California, USA\"\n",
      "        },\n",
      "        \"instance_type\": {\n",
      "          \"name\": \"gpu_1x_a10\",\n",
      "          \"description\": \"1x A10 (24 GB PCIe)\",\n",
      "          \"gpu_description\": \"A10 (24 GB PCIe)\",\n",
      "          \"price_cents_per_hour\": 75,\n",
      "          \"specs\": {\n",
      "            \"vcpus\": 30,\n",
      "            \"memory_gib\": 200,\n",
      "            \"storage_gib\": 1400,\n",
      "            \"gpus\": 1\n",
      "          }\n",
      "        },\n",
      "        \"hostname\": \"152-70-121-217.cloud.lambdalabs.com\",\n",
      "        \"jupyter_token\": \"0cda44f012f843b1be6ab6a801ea940b\",\n",
      "        \"jupyter_url\": \"https://jupyter-d72c51f0de5b4b17a5a0b7a48aa867b0.lambdaspaces.com/?token=0cda44f012f843b1be6ab6a801ea940b\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "BRANCH MANAGER DIDN'T DO ANYTHING\n",
      "BATCH MANAGER IS WORKING\n",
      "status of cluster: 2: COMPLETE\n",
      "cluster number 2 complete\n",
      "KILLING USELESS LAZY GUYS\n",
      "{\n",
      "  \"data\": {\n",
      "    \"terminated_instances\": [\n",
      "      {\n",
      "        \"id\": \"c07ca923c8a84ff1abc32629cff449b6\",\n",
      "        \"ip\": \"64.181.239.13\",\n",
      "        \"status\": \"terminating\",\n",
      "        \"ssh_key_names\": [\n",
      "          \"Srinivasan Sathiamurthy\"\n",
      "        ],\n",
      "        \"file_system_names\": [],\n",
      "        \"region\": {\n",
      "          \"name\": \"us-west-1\",\n",
      "          \"description\": \"California, USA\"\n",
      "        },\n",
      "        \"instance_type\": {\n",
      "          \"name\": \"gpu_1x_a10\",\n",
      "          \"description\": \"1x A10 (24 GB PCIe)\",\n",
      "          \"gpu_description\": \"A10 (24 GB PCIe)\",\n",
      "          \"price_cents_per_hour\": 75,\n",
      "          \"specs\": {\n",
      "            \"vcpus\": 30,\n",
      "            \"memory_gib\": 200,\n",
      "            \"storage_gib\": 1400,\n",
      "            \"gpus\": 1\n",
      "          }\n",
      "        },\n",
      "        \"hostname\": \"64-181-239-13.cloud.lambdalabs.com\",\n",
      "        \"jupyter_token\": \"3d4eb844bf0642f3969aa4b823e4f8ab\",\n",
      "        \"jupyter_url\": \"https://jupyter-668f21d67a1a409783ebb5c7d8bd8d9a.lambdaspaces.com/?token=3d4eb844bf0642f3969aa4b823e4f8ab\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "BRANCH MANAGER DIDN'T DO ANYTHING\n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "while(live_clusters):\n",
    "    print(\"BATCH MANAGER IS WORKING\")\n",
    "    time.sleep(60)\n",
    "    lazy_guys = []\n",
    "    failures = []\n",
    "    busy_guys = []\n",
    "    \n",
    "    for cluster_num in live_clusters:\n",
    "        tq = download_file_to_dict(f\"{bucket_name}-{cluster_num}\", f\"task_queue_{cluster_num}.json\")\n",
    "        temp_status = tq.get(\"status\", None)\n",
    "        print(f\"status of cluster: {cluster_num}: {temp_status}\")\n",
    "        if tq.get(\"status\", None) == \"NOT OK\":\n",
    "            print(f\"cluster number {cluster_num} failed\")\n",
    "            failures.append(cluster_num)\n",
    "        elif tq.get(\"status\", None) == \"COMPLETE\":\n",
    "            print(f\"cluster number {cluster_num} complete\")\n",
    "            lazy_guys.append(cluster_num)\n",
    "        else:\n",
    "            busy_guys.append(cluster_num)\n",
    "            \n",
    "    if len(failures) > 0 and (len(lazy_guys)+len(busy_guys)) > 0: #distribute tasks uniformly across all lazy and busy guys.\n",
    "        print(\"REDISTRIBUTING TASKS\")\n",
    "        failure_agg_task_queue = []\n",
    "        nonfailure_task_queue_dict = {}\n",
    "        for f in failures:\n",
    "            tf = download_file_to_dict(f\"{bucket_name}-{f}\", f\"task_queue_{f}.json\")[\"task_queue\"]\n",
    "            for t in tf:\n",
    "                failure_agg_task_queue.append((f, t))\n",
    "        for l in lazy_guys:\n",
    "            nonfailure_task_queue_dict[l] = download_file_to_dict(f\"{bucket_name}-{l}\", f\"task_queue_{l}.json\")[\"task_queue\"]\n",
    "        for b in busy_guys:\n",
    "            nonfailure_task_queue_dict[b] = download_file_to_dict(f\"{bucket_name}-{b}\", f\"task_queue_{b}.json\")[\"task_queue\"]\n",
    "        ftasklen = len(failure_agg_task_queue)\n",
    "        num_distributed = len(nonfailure_task_queue_dict)\n",
    "        print(f\"Redistributing {ftasklen} tasks to {num_distributed} workers\")\n",
    "        #distributes the tasks and files\n",
    "        for fatq in failure_agg_task_queue:\n",
    "            minc = -1\n",
    "            minval = 9999999999999 #a very fat number\n",
    "            for m in nonfailure_task_queue_dict:\n",
    "                if len(nonfailure_task_queue_dict[m]) < minval:\n",
    "                    minc = m\n",
    "                    minval = len(nonfailure_task_queue_dict[m])\n",
    "            assert(minc != -1) #should never happen, but just in case\n",
    "            nonfailure_task_queue_dict[minc].append(fatq[1])\n",
    "            move_s3_object(f\"{bucket_name}-{fatq[0]}\", fatq[1], f\"{bucket_name}-{minc}\", fatq[1])\n",
    "        \n",
    "        #updates the task queue jsons\n",
    "        for a in nonfailure_task_queue_dict:\n",
    "            print(f\"Updated task_queue_{a}.json\")\n",
    "            upload_dict_to_s3(f\"rapper-vkg-{a}\", f\"task_queue_{a}.json\", {\"task_queue\": nonfailure_task_queue_dict[a]})\n",
    "\n",
    "        #kill failures\n",
    "        for f in failures:\n",
    "            terminate_instance(f)\n",
    "            \n",
    "        live_clusters = list(set(live_clusters)-set(failures))\n",
    "    elif len(failures) > 0: #can't do shit. yer screwed.\n",
    "        #i didn't fully test this case: if this happens imma have to write more code anyway. global timeout should take care.\n",
    "        print(\"THE FORT HAS BEEN BREACHED. THERE IS NO HOPE. THE EMPIRE HAS FALLEN.\")\n",
    "        print(\"ok but in all seriousness, you have tasks on deadletter queue. you need to redistribute manually, or figure out what's wrong with your system.\")\n",
    "        failure_agg_task_queue_dict = defaultdict(list)\n",
    "        for f in failures:\n",
    "            tf = download_file_to_dict(f\"{bucket_name}-{f}\", f\"task_queue_{f}.json\")[\"task_queue\"]\n",
    "            for t in tf:\n",
    "                failure_agg_task_queue_dict[f].append(t)\n",
    "        with open(\"failed_tasks_dead_letter_queue.json\", 'w') as file: \n",
    "        \tjson.dump(failure_agg_task_queue_dict, file, indent=4)\n",
    "        for f in failures:\n",
    "            terminate_instance(f)\n",
    "\n",
    "    else: #kill all lazy guys\n",
    "        if len(lazy_guys) > 0:\n",
    "            print(\"KILLING USELESS LAZY GUYS\")\n",
    "            for l in lazy_guys:\n",
    "                terminate_instance(l)\n",
    "            live_clusters = list(set(live_clusters)-set(lazy_guys))\n",
    "        \n",
    "    e = time.time()\n",
    "    if e-s > global_timeout:\n",
    "        print(\"GLOBAL TIMEOUT REACHED\")\n",
    "        break\n",
    "    print(\"BRANCH MANAGER DIDN'T DO ANYTHING\")\n",
    "if live_clusters:\n",
    "    print(\"GLOBAL TIMEOUT REACHED, TERMINATING EVERYONE\")\n",
    "    for l in live_clusters:\n",
    "        terminate_instance(l)\n",
    "print(\"DONE!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
