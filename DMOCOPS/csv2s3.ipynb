{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6cbda701-fcca-4a11-b29b-fbac6c285b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError, PartialCredentialsError\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc25232-e7e9-4bce-82ce-9f98a77acd1a",
   "metadata": {},
   "source": [
    "## Some preprocessing code I'll include: not super relevant, but it's useful.\n",
    "\n",
    "**(goes from a bunch of txt files to csv)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c9d54252-d27a-44fc-ad46-4c7ffe747044",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "    \"kanye.txt\",\n",
    "    \"eminem.txt\",\n",
    "    \"denzel.txt\",\n",
    "    \"BIG.txt\",\n",
    "    \"biggie cheese.txt\",\n",
    "    \"tupac.txt\"\n",
    "]\n",
    "\n",
    "file_dict = defaultdict(list)\n",
    "\n",
    "for file_name in files:\n",
    "    with open(file_name, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    lines = [line.strip() for line in lines]\n",
    "    lines = [x for x in lines if x]\n",
    "    file_dict[file_name] = lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ad66ae56-0ce2-4b3f-bb04-11266369d930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134\n",
      "221\n",
      "52\n",
      "93\n",
      "136\n",
      "183\n"
     ]
    }
   ],
   "source": [
    "for k in file_dict:\n",
    "    print(len(file_dict[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0852e91d-035e-4c18-bffe-8e3c83e83d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAT\n",
      "FAT\n",
      "FAT\n",
      "FAT\n"
     ]
    }
   ],
   "source": [
    "chunked_dict = defaultdict(list)\n",
    "for k in file_dict:\n",
    "    text = []\n",
    "    for curtext in file_dict[k]:\n",
    "        curlen = len(curtext.split())\n",
    "        if curlen > 255:\n",
    "            print(\"FAT\")\n",
    "        curdenom = 1 + ((curlen)//256)\n",
    "        if len(curtext.split())%256 == 0:\n",
    "            curdenom = curdenom - 1\n",
    "        for j in range(curdenom):\n",
    "            text.append(\" \".join(curtext.split()[j*(curlen//curdenom):(j+1)*(curlen//curdenom)]))\n",
    "    chunked_dict[k] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5783d5c5-55b1-40c1-bfc3-15a12ed9febb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134\n",
      "134\n",
      "kanye.txt\n",
      "221\n",
      "225\n",
      "eminem.txt\n",
      "52\n",
      "52\n",
      "denzel.txt\n",
      "93\n",
      "93\n",
      "BIG.txt\n",
      "136\n",
      "136\n",
      "biggie cheese.txt\n",
      "183\n",
      "183\n",
      "tupac.txt\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for k in file_dict:\n",
    "    print(len(file_dict[k]))\n",
    "    print(len(chunked_dict[k]))\n",
    "    print(k)\n",
    "    cnt+=len(chunked_dict[k])\n",
    "#ait it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c78bf688-7501-4c86-9878-ac79bcd1639e",
   "metadata": {},
   "outputs": [],
   "source": [
    "person = []\n",
    "text = []\n",
    "fiction_or_not = []\n",
    "for k in file_dict:\n",
    "    for ele in file_dict[k]:\n",
    "        if k in [\"kanye.txt\", \"eminem.txt\", \"denzel.txt\", \"BIG.txt\", \"tupac.txt\"]:\n",
    "            fiction_or_not.append(\"True\")\n",
    "        else:\n",
    "            fiction_or_not.append(\"False\")\n",
    "        person.append(k)\n",
    "        text.append(ele)\n",
    "vkg_df = pd.DataFrame(data = {\"text\": text, \"person\": person, \"fiction_or_not\": fiction_or_not})\n",
    "vkg_df.to_csv(\"rapper_vkg.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59207e8-b0ee-4f84-8ea8-ec940b41a348",
   "metadata": {},
   "source": [
    "## csv2s3 Core Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cf402574-2c5b-4fbb-a981-a6c50f7a4655",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"rapper_vkg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "32bd7de0-557a-4129-8c2a-167cc10522d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['text'].apply(lambda x: len(x.split()) > 20)] #just some filtering from my end (data was not clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "09ecd47f-0793-4a3d-b238-78ae21e63713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "479"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "a2ba8e83-0369-47a4-b476-77f1f0e44e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "An error occurred (InvalidClientTokenId) when calling the GetCallerIdentity operation: The security token included in the request is invalid.\n"
     ]
    }
   ],
   "source": [
    "os.environ['AWS_ACCESS_KEY_ID'] = 'key1'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = 'key2'\n",
    "os.environ['AWS_DEFAULT_REGION'] = 'us-east-1'\n",
    "!aws sts get-caller-identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e277ea04-2915-4db1-93b1-93f9cc7bd8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "00432495-b8cd-4674-bfac-3e88cbe17c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bucket(bucket_name, region=None):\n",
    "    try:\n",
    "        if region:\n",
    "            s3.create_bucket(\n",
    "                Bucket=bucket_name,\n",
    "                # CreateBucketConfiguration={'LocationConstraint': region}\n",
    "            )\n",
    "        else:\n",
    "            s3.create_bucket(Bucket=bucket_name)\n",
    "        print(f'Bucket {bucket_name} created successfully.')\n",
    "    except s3.exceptions.BucketAlreadyExists:\n",
    "        print(f'Bucket {bucket_name} already exists.')\n",
    "    except s3.exceptions.BucketAlreadyOwnedByYou:\n",
    "        print(f'Bucket {bucket_name} is already owned by you.')\n",
    "    except (NoCredentialsError, PartialCredentialsError):\n",
    "        print('Credentials not available.')\n",
    "\n",
    "def list_buckets():\n",
    "    try:\n",
    "        response = s3.list_buckets()\n",
    "        buckets = [{'Name': bucket['Name'], 'CreationDate': bucket['CreationDate']} for bucket in response['Buckets']]\n",
    "        return buckets\n",
    "    except (NoCredentialsError, PartialCredentialsError):\n",
    "        print('Credentials not available.')\n",
    "        return []\n",
    "    except ClientError as e:\n",
    "        print(f'ClientError: {e}')\n",
    "        return []\n",
    "\n",
    "def upload_file(file_name, bucket_name, object_name=None):\n",
    "    if object_name is None:\n",
    "        object_name = file_name\n",
    "    try:\n",
    "        s3.upload_file(file_name, bucket_name, object_name)\n",
    "        print(f'File {file_name} uploaded to bucket {bucket_name} as {object_name}.')\n",
    "    except (NoCredentialsError, PartialCredentialsError):\n",
    "        print('Credentials not available.')\n",
    "\n",
    "# Function to download a file from a bucket\n",
    "def download_file(bucket_name, object_name, file_name):\n",
    "    try:\n",
    "        s3.download_file(bucket_name, object_name, file_name)\n",
    "        print(f'File {file_name} downloaded from bucket {bucket_name} as {object_name}.')\n",
    "    except (NoCredentialsError, PartialCredentialsError):\n",
    "        print('Credentials not available.')\n",
    "\n",
    "# Function to delete a file from a bucket\n",
    "def delete_file(bucket_name, object_name):\n",
    "    try:\n",
    "        s3.delete_object(Bucket=bucket_name, Key=object_name)\n",
    "        print(f'File {object_name} deleted from bucket {bucket_name}.')\n",
    "    except (NoCredentialsError, PartialCredentialsError):\n",
    "        print('Credentials not available.')\n",
    "\n",
    "# Function to delete a bucket\n",
    "def delete_bucket(bucket_name):\n",
    "    try:\n",
    "        s3.delete_bucket(Bucket=bucket_name)\n",
    "        print(f'Bucket {bucket_name} deleted successfully.')\n",
    "    except (NoCredentialsError, PartialCredentialsError):\n",
    "        print('Credentials not available.')\n",
    "\n",
    "def list_files(bucket_name):\n",
    "    s3 = boto3.client('s3')\n",
    "    file_names = []\n",
    "    response = s3.list_objects_v2(Bucket=bucket_name)\n",
    "    if 'Contents' in response:\n",
    "        for obj in response['Contents']:\n",
    "            file_names.append(obj['Key'])\n",
    "    \n",
    "    return file_names\n",
    "\n",
    "def upload_dict_to_s3(bucket_name, object_name, dictionary):\n",
    "    json_data = json.dumps(dictionary)\n",
    "    s3.put_object(Bucket=bucket_name, Key=object_name, Body=json_data)\n",
    "\n",
    "def download_file_to_dict(bucket_name, object_name):\n",
    "    try:\n",
    "        response = s3.get_object(Bucket=bucket_name, Key=object_name)\n",
    "        content = response['Body'].read().decode('utf-8')\n",
    "        data_dict = json.loads(content)\n",
    "        # print(f'File {object_name} downloaded from bucket {bucket_name} and converted to dictionary.')\n",
    "        return data_dict\n",
    "    except (NoCredentialsError, PartialCredentialsError):\n",
    "        print('Credentials not available.')\n",
    "    except Exception as e:\n",
    "        print(f'An error occurred: {e}')\n",
    "        return None\n",
    "\n",
    "def empty_bucket(bucket_name):\n",
    "    try:\n",
    "        s3 = boto3.client('s3')\n",
    "        s3_resource = boto3.resource('s3')\n",
    "        bucket = s3_resource.Bucket(bucket_name)\n",
    "\n",
    "        # Delete all objects in the bucket\n",
    "        bucket.objects.delete()\n",
    "\n",
    "\n",
    "        print(f'Bucket {bucket_name} has been emptied.')\n",
    "    except (NoCredentialsError, PartialCredentialsError):\n",
    "        print('Credentials not available.')\n",
    "    except Exception as e:\n",
    "        print(f'An error occurred: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "34bd54ea-5bae-4aff-8eda-970ccd5f9b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket rapper-vkg-0 created successfully.\n",
      "Bucket rapper-vkg-1 created successfully.\n",
      "Bucket rapper-vkg-2 created successfully.\n",
      "Bucket rapper-vkg-3 created successfully.\n",
      "Bucket rapper-vkg-4 created successfully.\n",
      "Bucket rapper-vkg-5 created successfully.\n",
      "Bucket rapper-vkg-6 created successfully.\n"
     ]
    }
   ],
   "source": [
    "region = 'us-east-1'\n",
    "bucket_name = \"rapper-vkg\"\n",
    "num_batches = 7\n",
    "for i in range(num_batches):\n",
    "    create_bucket(bucket_name+f\"-{i}\", region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "fde0f6f0-ca1f-4f30-9c3c-ee9ecd87d835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n"
     ]
    }
   ],
   "source": [
    "for idx in range(len(df)):\n",
    "    if idx%10 == 0:\n",
    "        print(idx)\n",
    "    modnum = idx%num_batches\n",
    "    upload_dict_to_s3(bucket_name+f\"-{modnum}\", f\"data_{idx}.json\", df.iloc[idx].to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "294f1d89-e65b-4baf-bff3-aadfc055cd72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n",
      "69\n",
      "69\n",
      "68\n",
      "68\n",
      "68\n",
      "68\n"
     ]
    }
   ],
   "source": [
    "task_queues = defaultdict(list)\n",
    "for idx in range(len(df)):    \n",
    "    modnum = idx%num_batches\n",
    "    task_queues[modnum].append(f\"data_{idx}.json\")\n",
    "for i in range(num_batches):\n",
    "    print(len(task_queues[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "52b5b21e-7c37-49fb-a937-61b0102cfb31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL OK\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_batches):\n",
    "    td = {\n",
    "        \"task_queue\": task_queues[i]\n",
    "    }\n",
    "    upload_dict_to_s3(bucket_name+f\"-{i}\", f\"task_queue_{i}.json\", td)\n",
    "print(\"ALL OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a6d0f4-b469-4e3e-b6f9-db8d3bf99269",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample code- just prevents annoying copy pasting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "b15ad5b8-6c40-4b0b-a8e8-295a6fa5a95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "479\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "3f2bf2a6-c882-4d63-aa3d-998a608031b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket rapper-vkg-0 has been emptied.\n",
      "Bucket rapper-vkg-0-results has been emptied.\n",
      "Bucket rapper-vkg-0 deleted successfully.\n",
      "Bucket rapper-vkg-0-results deleted successfully.\n",
      "Bucket rapper-vkg-1 has been emptied.\n",
      "Bucket rapper-vkg-1-results has been emptied.\n",
      "Bucket rapper-vkg-1 deleted successfully.\n",
      "Bucket rapper-vkg-1-results deleted successfully.\n",
      "Bucket rapper-vkg-2 has been emptied.\n",
      "Bucket rapper-vkg-2-results has been emptied.\n",
      "Bucket rapper-vkg-2 deleted successfully.\n",
      "Bucket rapper-vkg-2-results deleted successfully.\n",
      "Bucket rapper-vkg-3 has been emptied.\n",
      "Bucket rapper-vkg-3-results has been emptied.\n",
      "Bucket rapper-vkg-3 deleted successfully.\n",
      "Bucket rapper-vkg-3-results deleted successfully.\n",
      "Bucket rapper-vkg-4 has been emptied.\n",
      "Bucket rapper-vkg-4-results has been emptied.\n",
      "Bucket rapper-vkg-4 deleted successfully.\n",
      "Bucket rapper-vkg-4-results deleted successfully.\n",
      "Bucket rapper-vkg-5 has been emptied.\n",
      "Bucket rapper-vkg-5-results has been emptied.\n",
      "Bucket rapper-vkg-5 deleted successfully.\n",
      "Bucket rapper-vkg-5-results deleted successfully.\n",
      "Bucket rapper-vkg-6 has been emptied.\n",
      "Bucket rapper-vkg-6-results has been emptied.\n",
      "Bucket rapper-vkg-6 deleted successfully.\n",
      "Bucket rapper-vkg-6-results deleted successfully.\n"
     ]
    }
   ],
   "source": [
    "#DON'T RUN THIS: JUST FOR MY TESTING\n",
    "for i in range(num_batches):\n",
    "    empty_bucket(f\"rapper-vkg-{i}\")\n",
    "    empty_bucket(f\"rapper-vkg-{i}-results\")\n",
    "    delete_bucket(f\"rapper-vkg-{i}\")\n",
    "    delete_bucket(f\"rapper-vkg-{i}-results\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
